# Dify

::::details 参考资料：

- [Dify](https://dify.ai/zh)
- [Dify官方文档](https://docs.dify.ai/zh-hans)
- [Dify知识库详解](https://z0yrmerhgi8.feishu.cn/wiki/FPsVw9gsCi6SIykwg2Ccnk8ln2g)

::::

**Dify** 是一款开源的大语言模型(LLM) 应用开发平台。它融合了后端即服务（Backend as Service）和 [LLMOps](https://docs.dify.ai/zh-hans/learn-more/extended-reading/what-is-llmops) 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。

它提供了可视化的编排工具，支持多种 AI 模型（如 OpenAI、Anthropic、本地部署的模型等），并允许用户通过简单的界面创建 AI 驱动的应用，如聊天机器人、知识库助手、自动化工作流等。

## 知识库

### 1.知识库是什么？

知识库（`Knowledge Base`）是智能运维的核心组件，本质是一个`结构化`、`可检索`的`信息库`，用于`存储`运维相关的经验、解决方案、日志规则、故障处理流程等。

本质就是使用者将文档上传至知识库后进行`结构化处理`，供后续的 LLM 查询。

LLM 接收到用户的问题后，将首先基于关键词在知识库内检索内容。知识库将根据关键词，召回相关度排名较高的内容区块，向 LLM 提供关键上下文以辅助其生成更加精准的回答。

### 2.创建知识库

[创建知识库](https://docs.dify.ai/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents)并上传文档分为以下步骤：

- 创建知识库，通过上传本地文件、导入在线数据或创建一个空的知识库
- 导入文本数据
  - 上传本地文件 or 导入在线数据
- 指定分段模式
  - 内容的预处理与数据结构化过程，长文本将会被划分为多个内容分段，可以在此环节预览文本的分段效果
- 设定索引方法和检索设置
  - 知识库在接收到用户查询问题后，按照预设的检索方式在已有的文档内查找相关内容，提取出高度相关的信息片段供语言模型生成高质量答案
- 完成上传，在应用内关联知识库并使用

#### 2.1.指定分段模式

指定分段模式就是对内容进行**分段**与**数据清洗**。

「分段」是由于大语言模型的上下文窗口有限，无法一次性处理和传输整个知识库的内容。

经过分段后，知识库能够基于用户问题，**采用分段 TopK 召回模式**，召回与问题高度相关的内容块，补全关键信息从而提高回答的精准性。

在进行问题与内容块的语义匹配时，**合理的分段大小非常关键**，它能够帮助模型准确地找到与问题最相关的内容，减少噪音信息。过大或过小的分段都可能影响召回的效果。

「数据清洗」是将文本内容中存在无意义的字符或者空行进行清洗，保证文本召回的效果。

#### 2.2.索引方式

「索引方式」是把清洗并分段后的数据转成“向量”的过程，即：

- 使用大语言模型（如 OpenAI 的 text-embedding-ada-002）将每个段落转成向量（embedding 向量）
- 同时提取关键词用于辅助搜索
- 这些向量及其元数据（如来源、段落原文）存入向量数据库（如 FAISS、Milvus、Weaviate、Qdrant 等）

✅ 目的：让每个知识块拥有语义表示，支持相似度匹配。

#### 2.3.检索设置

这是指用户与知识库交互时，Dify 如何从向量库中找出相关内容：

- 检索模型设置：例如是用“向量相似度检索（Vector Search）”还是“混合检索（Hybrid）”
- 检索方式：支持 top-k 检索（取前 K 个相似段落），有些还能加权关键词或内容重要性
- 是否添加 rerank（重排序）：部分系统支持用大模型对初步检索结果做 rerank 排序提升质量

✅ 最终的目标：从向量库中找出最相关的段落，提供给大模型进行问答生成（RAG）。

### 3.